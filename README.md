# ğŸ“± Fintech App Review Analysis â€“ Week 2

This project is part of the **10 Academy AI Mastery Week 2 Challenge**, where the goal is to analyze Google Play Store reviews for three major Ethiopian banking apps â€” **CBE**, **BOA**, and **Dashen Bank** â€” to extract insights that can improve customer experience.

---

## ğŸ¯ Project Objective

- Scrape user reviews from the Play Store
- Clean and preprocess the review text
- Perform sentiment analysis and thematic grouping
- Store the processed data in a structured Oracle database
- Visualize insights and provide recommendations to each bank

---

## ğŸ› ï¸ Tools & Libraries

- `google-play-scraper` â€“ for scraping app reviews
- `pandas`, `numpy` â€“ data processing
- `matplotlib`, `seaborn`, `wordcloud` â€“ data visualization
- `TextBlob`, `NLTK`, `VADER`, `TextBlob`, `TF-IDF`, `SpaCy` â€“ sentiment & theme extraction
- `cx_Oracle` â€“ connecting to Oracle XE database

---
## ğŸ§ª Methodology

### ğŸ”¹ Data Scraping

We used the `google-play-scraper` Python library to extract user reviews for three Ethiopian banking apps: **CBE**, **BOA**, and **Dashen Bank**. For each app, over 400 reviews were collected to ensure diversity and volume.

Key fields extracted:
- `review`: User-written review content
- `rating`: Integer rating (1 to 5)
- `date`: Date the review was posted
- `source`: Set to "Google Play"
- `bank`: One of "CBE", "BOA", or "Dashen"

The scraping was done in batches and saved as raw `.csv` files per app in the `data/raw_reviews/` folder.

---

### ğŸ”¹ Data Cleaning & Preprocessing

After scraping, each dataset underwent preprocessing to ensure quality and consistency.

Steps included:
- **Removing Duplicates**: Eliminated repeated reviews based on text content.
- **Standardizing Text**: Converted reviews to lowercase, removed URLs, non-ASCII characters, and excess whitespace.
- **Filtering Noise**: Removed reviews with fewer than 3 words or missing key fields (e.g., no rating or date).
- **Parsing Dates**: Standardized review dates using `pandas.to_datetime()`.
- **Labeling**: Appended `bank` and `source` columns to each row to ensure traceability.

The cleaned data was saved in `data/cleaned/` and combined into a single master file:  
`all_clean_reviews.csv`

This cleaned dataset is the basis for sentiment analysis, thematic grouping, and database storage.
---

## ğŸ“‚ Folder Structure

project/  
â”œâ”€â”€ data/  
â”‚ â”œâ”€â”€ raw_reviews/  
â”‚ â”œâ”€â”€ cleaned/  
â”‚ â””â”€â”€ sentiment/  
â”œâ”€â”€ notebooks/  
â”‚ â”œâ”€â”€ task1_scraping_eda.ipynb  
â”‚ â”œâ”€â”€ task2_sentiment_theme.ipynb  
â”‚ â”œâ”€â”€ task3_oracle_storage.ipynb  
â”‚ â””â”€â”€ task4_insights_report.ipynb  
â”œâ”€â”€ scripts/  
â”‚ â”œâ”€â”€ scrape_reviews.py  
â”‚ â”œâ”€â”€ clean_reviews.py  
â”‚ â”œâ”€â”€ sentiment_analysis.py  
â”‚ â””â”€â”€ upload_to_oracle.py  
â”œâ”€â”€ reports/  
â”‚ â””â”€â”€ final_report.pdf  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md  